epoch,train_loss,val_loss,val_acc
1,1.2891764640808105,0.6925169825553894,50.0
2,1.2791621685028076,0.6874546408653259,66.66666666666666
3,1.2749545574188232,0.6820956468582153,66.66666666666666
4,1.2680705785751343,0.6772177219390869,66.66666666666666
5,1.261318564414978,0.6726840734481812,66.66666666666666
6,1.2557896375656128,0.6682261824607849,66.66666666666666
7,1.248437762260437,0.6639456152915955,66.66666666666666
8,1.2545901536941528,0.6598551869392395,66.66666666666666
9,1.2379800081253052,0.6558048129081726,66.66666666666666
10,1.2117207050323486,0.6514812707901001,66.66666666666666
11,1.2320027351379395,0.6510326862335205,66.66666666666666
12,1.2187020778656006,0.6505849361419678,66.66666666666666
13,1.2432326078414917,0.6501305103302002,66.66666666666666
14,1.2126449346542358,0.649664044380188,66.66666666666666
15,1.2199636697769165,0.6492289900779724,66.66666666666666
16,1.2093470096588135,0.6488127112388611,66.66666666666666
17,1.2202292680740356,0.6484097242355347,66.66666666666666
18,1.216482400894165,0.6480135917663574,66.66666666666666
19,1.2181856632232666,0.6476184129714966,66.66666666666666
20,1.2063099145889282,0.6472148299217224,66.66666666666666
