epoch,train_loss,val_loss,val_acc_05
1,0.6730648279190063,0.6580601930618286,91.66666666666666
2,0.6545006632804871,0.6409038305282593,91.66666666666666
3,0.6349892616271973,0.6237107515335083,91.66666666666666
4,0.6208717226982117,0.606257438659668,91.66666666666666
5,0.6001368463039398,0.5890419483184814,91.66666666666666
6,0.5824851095676422,0.5713590383529663,91.66666666666666
7,0.573146402835846,0.553002119064331,91.66666666666666
8,0.5491001904010773,0.5342017412185669,91.66666666666666
9,0.5329249501228333,0.5148684978485107,91.66666666666666
10,0.5111225843429565,0.4950627088546753,91.66666666666666
11,0.4945262372493744,0.49303922057151794,91.66666666666666
12,0.49602699279785156,0.4909992814064026,91.66666666666666
13,0.48753462731838226,0.48896676301956177,91.66666666666666
14,0.4916895776987076,0.4869222640991211,91.66666666666666
15,0.4867280125617981,0.4848904609680176,91.66666666666666
16,0.48275718092918396,0.4828542172908783,91.66666666666666
17,0.48120570182800293,0.4808077812194824,91.66666666666666
18,0.48285698890686035,0.47875937819480896,91.66666666666666
19,0.48290112614631653,0.4767173230648041,91.66666666666666
20,0.4712878316640854,0.47468578815460205,91.66666666666666
