epoch,train_loss,val_loss,val_acc
1,0.5838662981987,0.5698151588439941,57.14285714285714
2,0.58649742603302,0.5685735940933228,57.14285714285714
3,0.6298210322856903,0.568841278553009,57.14285714285714
4,0.5712957382202148,0.5684568285942078,57.14285714285714
5,0.6243882179260254,0.5678803324699402,57.14285714285714
6,0.5659185349941254,0.5666218996047974,57.14285714285714
7,0.5727817714214325,0.5640358328819275,71.42857142857143
8,0.5573859214782715,0.56183922290802,85.71428571428571
9,0.5215128362178802,0.5605759024620056,85.71428571428571
10,0.6158713698387146,0.5585826635360718,85.71428571428571
11,0.6114062368869781,0.5582953691482544,85.71428571428571
12,0.598579466342926,0.5579485893249512,85.71428571428571
13,0.5184526443481445,0.5575897693634033,85.71428571428571
14,0.5930609107017517,0.5572304129600525,85.71428571428571
15,0.5679960548877716,0.556829035282135,85.71428571428571
16,0.5798678994178772,0.5564703345298767,85.71428571428571
17,0.552135556936264,0.5561167001724243,85.71428571428571
18,0.576786994934082,0.555734395980835,85.71428571428571
19,0.527877151966095,0.5553917288780212,85.71428571428571
20,0.5744403004646301,0.555062472820282,85.71428571428571
