epoch,train_loss,val_loss,val_acc_05
1,0.6717197299003601,0.6879585981369019,66.66666666666666
2,0.6657190322875977,0.6861924529075623,66.66666666666666
3,0.6598009467124939,0.6845446825027466,66.66666666666666
4,0.6538646817207336,0.6827840805053711,66.66666666666666
5,0.6478450894355774,0.6811195611953735,66.66666666666666
6,0.6418437957763672,0.6792697906494141,66.66666666666666
7,0.6358780860900879,0.6772035360336304,66.66666666666666
8,0.6298913359642029,0.6752526164054871,66.66666666666666
9,0.6237654685974121,0.6734492778778076,83.33333333333334
10,0.617531418800354,0.6717244982719421,83.33333333333334
11,0.6112841963768005,0.671565055847168,83.33333333333334
12,0.6106563210487366,0.6714012026786804,83.33333333333334
13,0.6100255846977234,0.6712254881858826,83.33333333333334
14,0.6093902587890625,0.6710559725761414,83.33333333333334
15,0.6087508797645569,0.670891523361206,83.33333333333334
16,0.6081073880195618,0.6707315444946289,83.33333333333334
17,0.6074596643447876,0.6705783605575562,83.33333333333334
18,0.6068099737167358,0.6704174280166626,83.33333333333334
19,0.6061576008796692,0.6702598333358765,83.33333333333334
20,0.605503261089325,0.6701034307479858,83.33333333333334
