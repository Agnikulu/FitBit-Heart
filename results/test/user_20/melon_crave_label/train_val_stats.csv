epoch,train_loss,val_loss,val_acc_05
1,0.6698294878005981,0.6592742800712585,83.33333333333334
2,0.66095370054245,0.6535019278526306,83.33333333333334
3,0.6523669362068176,0.6481410264968872,83.33333333333334
4,0.644059956073761,0.6430923938751221,83.33333333333334
5,0.6361223459243774,0.6382572054862976,83.33333333333334
6,0.6282650828361511,0.6343350410461426,83.33333333333334
7,0.620701014995575,0.630890429019928,83.33333333333334
8,0.6132428050041199,0.6276234984397888,83.33333333333334
9,0.6058191657066345,0.6245586276054382,83.33333333333334
10,0.5984838604927063,0.6216475367546082,83.33333333333334
11,0.5912792086601257,0.6213687658309937,83.33333333333334
12,0.5905672311782837,0.6211013197898865,83.33333333333334
13,0.5898499488830566,0.6208490133285522,83.33333333333334
14,0.5891339182853699,0.6206095218658447,83.33333333333334
15,0.5884165167808533,0.6203799247741699,83.33333333333334
16,0.5876978039741516,0.6201598644256592,83.33333333333334
17,0.5869790315628052,0.6199479103088379,83.33333333333334
18,0.5862647294998169,0.6197507381439209,83.33333333333334
19,0.5855512619018555,0.6195666790008545,83.33333333333334
20,0.584837019443512,0.6193947196006775,83.33333333333334
